#!/usr/bin/env python3
"""
Viewpoints to TSP Solver

Loads pre-computed viewpoints from HDF5 file (generated by mesh_to_viewpoints.py)
and solves the Traveling Salesman Problem to find an optimal visit order.

Supported algorithms:
- Nearest Neighbor (NN): Fast greedy heuristic
- Random Insertion (RI): Better quality, slower

Coordinate system:
- Input: Z-up coordinates (from mesh_to_viewpoints.py)
- Output: TSP-ordered tour in Z-up coordinates
"""

import os
import sys
import argparse
import numpy as np
import torch
from typing import Tuple

# Add parent directory to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Import TSP utilities for saving/loading results
from tsp_utils import save_tsp_result, load_viewpoints


def normalize_coordinates(points: np.ndarray) -> Tuple[np.ndarray, dict]:
    """
    Normalize point coordinates to [0, 1] range

    Args:
        points: (N, 3) array

    Returns:
        normalized_points: (N, 3) array in [0, 1]
        normalization_info: dict with min/max for denormalization
    """
    min_coords = points.min(axis=0)
    max_coords = points.max(axis=0)

    # Normalize to [0, 1]
    normalized = (points - min_coords) / (max_coords - min_coords + 1e-8)

    normalization_info = {
        'min': min_coords,
        'max': max_coords
    }

    return normalized, normalization_info


def denormalize_coordinates(points: np.ndarray, normalization_info: dict) -> np.ndarray:
    """Denormalize coordinates back to original scale"""
    min_coords = normalization_info['min']
    max_coords = normalization_info['max']
    return points * (max_coords - min_coords) + min_coords


def compute_tour_length(points: np.ndarray, tour: np.ndarray) -> float:
    """
    Compute total tour length

    Args:
        points: (N, 3) array
        tour: (N,) array or tensor of node indices

    Returns:
        length: total Euclidean distance
    """
    if isinstance(tour, torch.Tensor):
        tour = tour.cpu().numpy()

    # Reorder points according to tour
    ordered_points = points[tour]

    # Compute distances between consecutive points
    distances = np.linalg.norm(ordered_points[1:] - ordered_points[:-1], axis=1)

    # Add distance from last to first (close the loop)
    closing_distance = np.linalg.norm(ordered_points[-1] - ordered_points[0])

    total_length = distances.sum() + closing_distance
    return float(total_length)


def calc_pairwise_distances(points: torch.Tensor) -> torch.Tensor:
    """
    Calculate pairwise Euclidean distances between all points

    Args:
        points: (N, 3) or (batch, N, 3) tensor

    Returns:
        dist: (N, N) or (batch, N, N) tensor of pairwise distances
    """
    if points.dim() == 2:
        # (N, 3) -> (N, N)
        diff = points.unsqueeze(1) - points.unsqueeze(0)  # (N, N, 3)
        dist = torch.sqrt((diff ** 2).sum(dim=-1))  # (N, N)
    else:
        # (batch, N, 3) -> (batch, N, N)
        diff = points.unsqueeze(2) - points.unsqueeze(1)  # (batch, N, N, 3)
        dist = torch.sqrt((diff ** 2).sum(dim=-1))  # (batch, N, N)

    return dist


def nearest_neighbor_torch(points: torch.Tensor, start_idx: int = 0) -> torch.Tensor:
    """
    Vectorized Nearest Neighbor algorithm using PyTorch
    Based on the original GLOP implementation but simplified

    Args:
        points: (N, 3) tensor of point coordinates
        start_idx: Starting point index

    Returns:
        tour: (N,) tensor of node indices representing the tour
    """
    device = points.device
    n = len(points)

    # Precompute all pairwise distances
    dist = calc_pairwise_distances(points)  # (N, N)

    # Initialize
    current = torch.tensor([start_idx], dtype=torch.long, device=device)
    dist_to_start = dist[start_idx].clone()
    tour = [current]

    # Build tour greedily
    for i in range(n - 1):
        # Mark current node as visited (set distance to infinity)
        dist[:, current] = float('inf')

        # Get distances from current node to all others
        nn_dist = dist[current].squeeze(0)  # (N,)

        # Find nearest unvisited node
        current = nn_dist.argmin().unsqueeze(0)
        tour.append(current)

    # Stack tour into single tensor
    tour = torch.cat(tour)  # (N,)

    return tour


def generate_multiple_nn_tours_torch(points: torch.Tensor, num_starts: int = 10) -> list:
    """
    Generate multiple NN tours with different random starting points using PyTorch

    Args:
        points: (N, 3) tensor of point coordinates
        num_starts: Number of different starting points to try

    Returns:
        tours: List of (tour, cost) tuples, where tour is a tensor
    """
    n = len(points)
    tours = []

    # Use different starting points
    if num_starts >= n:
        start_indices = list(range(n))
    else:
        # Random selection of starting points
        torch.manual_seed(42)
        start_indices = torch.randperm(n)[:num_starts].tolist()

    for start_idx in start_indices:
        tour = nearest_neighbor_torch(points, start_idx)
        cost = compute_tour_length(points.cpu().numpy(), tour.cpu().numpy())
        tours.append((tour, cost))

    return tours


def random_insertion_torch(points: torch.Tensor, seed: int = 0) -> torch.Tensor:
    """
    Vectorized Random Insertion heuristic for TSP using PyTorch (GPU-accelerated)

    Algorithm:
    1. Start with a partial tour of 3 random points (forming a triangle)
    2. Randomly select a remaining point
    3. Insert it at the position that minimizes tour length increase (vectorized calculation)
    4. Repeat until all points are in the tour

    Key optimization: All insertion positions are evaluated in parallel using GPU

    Args:
        points: (N, 3) tensor of point coordinates
        seed: Random seed for reproducibility

    Returns:
        tour: (N,) tensor of node indices representing the tour
    """
    device = points.device
    n = len(points)

    # Precompute distance matrix once (stays on GPU)
    dist_matrix = calc_pairwise_distances(points)  # (N, N)

    # Set random seed
    torch.manual_seed(seed)

    # Start with 3 random points forming initial tour
    initial_indices = torch.randperm(n, device=device)[:3]
    tour = initial_indices.clone()  # Keep as tensor for GPU operations

    # Create mask for remaining points
    remaining_mask = torch.ones(n, dtype=torch.bool, device=device)
    remaining_mask[initial_indices] = False

    # Get remaining indices and shuffle them
    remaining_indices = torch.nonzero(remaining_mask).squeeze(1)
    torch.manual_seed(seed + 1)
    perm = torch.randperm(len(remaining_indices), device=device)
    remaining_indices = remaining_indices[perm]

    # Insert remaining points one by one
    for point_idx in remaining_indices:
        tour_len = len(tour)

        # Vectorized calculation of insertion cost for ALL positions
        # Current edges: tour[i] -> tour[i+1]
        indices_before = tour  # (tour_len,)
        indices_after = torch.cat([tour[1:], tour[0:1]])  # Circular shift: (tour_len,)

        # Cost of current edges
        current_edges_cost = dist_matrix[indices_before, indices_after]  # (tour_len,)

        # Cost of new edges if we insert point_idx between tour[i] and tour[i+1]
        # New edges: tour[i] -> point_idx -> tour[i+1]
        new_edge1_cost = dist_matrix[indices_before, point_idx]  # (tour_len,)
        new_edge2_cost = dist_matrix[point_idx, indices_after]   # (tour_len,)

        # Calculate cost increase for each insertion position (vectorized!)
        cost_increases = new_edge1_cost + new_edge2_cost - current_edges_cost  # (tour_len,)

        # Find position with minimum cost increase
        best_pos = cost_increases.argmin().item()

        # Insert point at best position (tensor concatenation)
        # Insert after position best_pos
        tour = torch.cat([
            tour[:best_pos + 1],
            point_idx.unsqueeze(0),
            tour[best_pos + 1:]
        ])

    return tour


def generate_multiple_random_insertion_tours(points: torch.Tensor, num_starts: int = 10) -> list:
    """
    Generate multiple Random Insertion tours with different random seeds

    Args:
        points: (N, 3) tensor of point coordinates
        num_starts: Number of different random seeds to try

    Returns:
        tours: List of (tour, cost) tuples, where tour is a tensor
    """
    tours = []

    for seed in range(num_starts):
        tour = random_insertion_torch(points, seed=seed)
        cost = compute_tour_length(points.cpu().numpy(), tour.cpu().numpy())
        tours.append((tour, cost))

    return tours


def solve_tsp_with_heuristics(
    points: np.ndarray,
    algorithm: str = 'both',
    num_starts: int = 10,
    device: str = 'cuda'
) -> Tuple[np.ndarray, float, str]:
    """
    Solve TSP using heuristic algorithms (NN and/or Random Insertion)

    Algorithm:
    1. Convert points to PyTorch tensor and move to GPU if available
    2. Run selected algorithm(s): nn, ri, or both
    3. Select and return the best tour

    Args:
        points: (N, 3) normalized coordinates (NumPy array)
        algorithm: Which algorithm to use ('nn', 'ri', or 'both')
        num_starts: Number of initial solutions to generate
        device: 'cuda' or 'cpu'

    Returns:
        best_tour: (N,) array of node indices
        best_cost: Tour cost
        algorithm_used: Name of algorithm that produced best tour
    """
    # Convert to PyTorch tensor and move to device
    if device == 'cuda' and torch.cuda.is_available():
        points_tensor = torch.from_numpy(points).float().cuda()
        print(f"Using GPU acceleration (CUDA)")
    else:
        points_tensor = torch.from_numpy(points).float()
        print(f"Using CPU")

    print(f"\n{'=' * 60}")
    print(f"Algorithm: {algorithm}")
    print(f"{'=' * 60}")

    all_tours = []
    algorithm_labels = []

    # Run Nearest Neighbor if requested
    if algorithm in ['nn', 'both']:
        print(f"\nGenerating {num_starts} Nearest Neighbor solutions...")
        nn_tours = generate_multiple_nn_tours_torch(points_tensor, num_starts)

        nn_costs = [cost for _, cost in nn_tours]
        print(f"  Best NN cost: {min(nn_costs):.6f}")
        print(f"  Worst NN cost: {max(nn_costs):.6f}")
        print(f"  Average NN cost: {np.mean(nn_costs):.6f}")

        all_tours.extend(nn_tours)
        algorithm_labels.extend(['NN'] * len(nn_tours))

    # Run Random Insertion if requested
    if algorithm in ['ri', 'both']:
        print(f"\nGenerating {num_starts} Random Insertion solutions...")
        ri_tours = generate_multiple_random_insertion_tours(points_tensor, num_starts)

        ri_costs = [cost for _, cost in ri_tours]
        print(f"  Best RI cost: {min(ri_costs):.6f}")
        print(f"  Worst RI cost: {max(ri_costs):.6f}")
        print(f"  Average RI cost: {np.mean(ri_costs):.6f}")

        all_tours.extend(ri_tours)
        algorithm_labels.extend(['Random Insertion'] * len(ri_tours))

    # Select the best tour
    all_costs = [cost for _, cost in all_tours]
    best_idx = np.argmin(all_costs)
    best_tour, best_cost = all_tours[best_idx]
    best_algorithm = algorithm_labels[best_idx]

    print(f"\nSelected best tour: {best_algorithm} (cost: {best_cost:.6f})")

    # Convert back to NumPy array for compatibility
    best_tour_np = best_tour.cpu().numpy()

    return best_tour_np, best_cost, best_algorithm


def main():
    parser = argparse.ArgumentParser(
        description='Viewpoints to TSP Solver - Converts pre-computed viewpoints to optimized tour'
    )
    parser.add_argument('--viewpoint_file', type=str, required=True,
                        help='Path to viewpoints HDF5 file (generated by mesh_to_viewpoints.py)')
    parser.add_argument('--algorithm', type=str, default='both',
                        choices=['nn', 'ri', 'both'],
                        help='Algorithm to use: nn (Nearest Neighbor), ri (Random Insertion), or both (default: both)')
    parser.add_argument('--num_starts', type=int, default=10,
                        help='Number of initial solutions to generate (default: 10)')
    parser.add_argument('--device', type=str, default='cuda',
                        choices=['cuda', 'cpu'],
                        help='Device to run on: cuda or cpu (default: cuda)')
    parser.add_argument('--save_path', type=str, default=None,
                        help='Path to save TSP result as HDF5 file (default: auto-generated based on viewpoint count)')

    args = parser.parse_args()

    # Check if CUDA is available
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("CUDA not available, falling back to CPU")
        args.device = 'cpu'

    print("=" * 60)
    print("Viewpoints to TSP Solver")
    print("=" * 60)

    # Load pre-computed viewpoints from HDF5
    print(f"Loading viewpoints from: {args.viewpoint_file}")
    points, normals, metadata = load_viewpoints(args.viewpoint_file)
    mesh_file_path = metadata['mesh_file']
    print(f"Loaded {len(points)} viewpoints")
    print(f"Source mesh: {mesh_file_path}")

    # Normalize coordinates
    print("\nNormalizing coordinates to [0, 1]...")
    normalized_points, norm_info = normalize_coordinates(points)

    print(f"Original coordinate range:")
    print(f"  X: [{points[:, 0].min():.3f}, {points[:, 0].max():.3f}]")
    print(f"  Y: [{points[:, 1].min():.3f}, {points[:, 1].max():.3f}]")
    print(f"  Z: [{points[:, 2].min():.3f}, {points[:, 2].max():.3f}]")

    # Solve TSP using selected heuristic algorithm(s)
    print("\n" + "=" * 60)
    print("Solving TSP")
    print("=" * 60)
    tour, tour_cost, best_algorithm = solve_tsp_with_heuristics(
        normalized_points,
        args.algorithm,
        args.num_starts,
        args.device
    )

    # Print results
    print("\n" + "=" * 60)
    print("RESULTS")
    print("=" * 60)
    print(f"Number of viewpoints: {len(points)}")
    print(f"Algorithm: {args.algorithm}")
    print(f"Number of starts: {args.num_starts}")
    print(f"Best algorithm: {best_algorithm}")
    print(f"Tour cost: {tour_cost:.6f}")
    print("=" * 60)

    # Determine save path
    if args.save_path is None:
        # Auto-generate save path with num_points subdirectory
        num_points = len(points)
        output_dir = f'data/tour/{num_points}'
        os.makedirs(output_dir, exist_ok=True)
        args.save_path = f'{output_dir}/tour.h5'
        print(f"\nAuto-generated save path: {args.save_path}")

    # Extract camera_spec from metadata if available
    camera_spec_dict = None
    if 'camera_spec' in metadata:
        camera_spec_dict = metadata['camera_spec']
        print(f"\n{'='*60}")
        print("PROPAGATING CAMERA SPEC TO TSP FILE")
        print(f"{'='*60}")
        print(f"Camera spec found in viewpoints file:")
        if 'working_distance_mm' in camera_spec_dict:
            print(f"  Working distance: {camera_spec_dict['working_distance_mm']} mm")
        if 'fov_width_mm' in camera_spec_dict:
            print(f"  FOV: {camera_spec_dict['fov_width_mm']} x {camera_spec_dict.get('fov_height_mm', 'N/A')} mm")
        print(f"This will be saved to TSP file for subsequent pipeline stages")
        print(f"{'='*60}\n")

    # Save TSP result
    save_tsp_result(
        file_path=args.save_path,
        points_original=points,
        points_normalized=normalized_points,
        normalization_info=norm_info,
        normals=normals,
        tour_indices=tour,
        mesh_file=mesh_file_path,
        nn_cost=tour_cost,
        glop_cost=tour_cost,  # Store same cost for compatibility
        revision_lens=[],
        revision_iters=[],
        camera_spec=camera_spec_dict,
    )

    print("\nDone!")


if __name__ == "__main__":
    main()
